# -*- coding:utf-8 -*-

import os
import time
import urllib2
import socket
import traceback
from PIL import Image
from random import choice
from itertools import izip
from StringIO import StringIO
from contextlib import closing
from datetime import datetime
from django.conf import settings
from decimal import Decimal, getcontext
from xml.etree import cElementTree as ET
from tuangou.utils import app_error_log
from tuangou.guider.models import City, Deal, District, Shop

socket.setdefaulttimeout(20)

PRICE_FILTER = [',', u'折', u'￥', u'元', '-']

class SpiderBase(object):
    def _get_content(self, url):
        with closing(urllib2.urlopen(url)) as page:
            return page.read()

    def tryAgain(self, url, flag=None, retries=0):
        while True:
            if retries > 4: 
                if flag:
                    return ''
                else:
                    return ET.fromstring('<null></null>')
            try:
                time.sleep(1)
                content =self._get_content(url)
                if not flag:
                    content = ET.fromstring(content)
            except (urllib2.URLError, SyntaxError, ValueError, socket.error, socket.timeout):
                retries+=1
                content = self.tryAgain(url, flag, retries)
            return content

    def create_etree(self, url):
        content = self.get_content(url)
        try:
            etree = ET.fromstring(content)
        except SyntaxError:
            time.sleep(1)
            etree = self.tryAgain(url)
        return etree
            
    def get_content(self, url, flag=None):
        user_agents = [
            'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11',
            'Opera/9.25 (Windows NT 5.1; U; en)',
           "Mozilla/5.0 (X11; U; Linux x86_64; en-US; rv:1.9.2.17) Gecko/20110422 Ubuntu/10.04 (lucid) Firefox/3.6.17"
        ]
        headers = {'User-Agent':choice(user_agents)}
        req = urllib2.Request(url=url, headers=headers)
        try:
            content = self._get_content(req)
        except urllib2.HTTPError, e:
            if e.code == 503:
                time.sleep(1)
                content = self.tryAgain(req, flag)
            if e.code == 404:
                if not flag:
                    content = '<null></null>'
                else:
                    content = ''
        except (urllib2.URLError, socket.timeout, ValueError, socket.error):
            time.sleep(1)
            content = self.tryAgain(req, flag)
        return content

    def get_text(self, elem, tag):
        return elem.find(tag).text

    def get_elems(self, url):
        etree = self.create_etree(url)
        child_tree = etree.getchildren()
        childs = (child for child in child_tree if child.getchildren())
        return childs

class CitySpider(SpiderBase):
    def __init__(self, api_addr, api_list=None):
        self.api_addr = api_addr
        self.api_list = api_list

    def get_text(self, elem, tag):
        return list(elem.getiterator(tag))[0].text

    def create_related(self, site, name, api_name):
        city, flag = City.objects.get_or_create(name=name)
        api, flag = CityAPIName.objects.get_or_create(api_name=api_name)
        site.opened_city.add(city)
        site.cityapi.add(api)
        site.save()

    def get_field_map(self, site):
        field_map = dict(izip(settings.CITY_TUPLE, site.city_api_tags.split(',')))
        return field_map

    def _parse_city(self, site, elems):
        field_map = self.get_field_map(site)
        for elem in elems:
            api_name = self.get_text(elem, field_map[settings.CITY_API_NAME])
            name = self.get_text(elem, field_map[settings.CITY_NAME])
            self.create_related(site, name, api_name)

    def parse_city(self, site):
        if site.city_api:
            elems = self.get_elems(self.api_addr)
            self._parse_city(site, elems)

        if isinstance(self.api_list, list) or isinstance(self.api_list, tuple):
            for name in self.api_list:
                api_name, c = name.items()[0]
                self.create_related(site, c, api_name)

class DealSpider(SpiderBase):
    def __init__(self, deal_url):
        self.deal_url = deal_url

    def get_text(self, elem, field_map, tag):
        flag = False
        try:
            tag = field_map[tag]
        except KeyError:
            flag = True
        else:
            items = list(elem.getiterator(tag))
            len_items = len(items)
            if len_items == 1 or tag == 'description':
                try:
                    text = items[0].text
                except IndexError:
                    flag = True
                else:
                    return text
            elif len_items > 1:
                return items
            else:
                flag = True
        if flag:
            return ''

    def get_field_map(self, site):
        deal_map = {}
        fields = site.deal_map.all()
        for field in fields:
            deal_map[field.origin_field] = field.node
        return deal_map

    def filter_price(self, elem, field_map, tag, origin_price=None, price=None):
        scalar = self.get_text(elem, field_map, tag)
        if not scalar  and tag == settings.DEAL_DISCOUNT:
            getcontext().prec=3
            scalar  = origin_price * 10 / price
        else:
            try:
                for mark in PRICE_FILTER:
                    scalar = scalar.replace(mark, '')
            except:
                import pdb
                pdb.set_trace()
        try:
            return Decimal(scalar)
        except:
            return Decimal('0.0')

    def get_image(self, image_url, site):
        now = datetime.now()
        image_name = image_url.rsplit('/', 1)[-1]
        content = StringIO(self.get_content(image_url, flag='image'))
        try:
            image = Image.open(content)
        except IOError:
            return ''
        else:
            image = image.resize(settings.IMAGE_SIZE)
            image_sub_path = "%s/%s/%s/%s" % (now.year, now.strftime('%m'), now.strftime('%d'), site.slug)
            image_dirs = "%s/%s" % (settings.MEDIA_ROOT, image_sub_path)
            if not os.path.exists(image_dirs):
                os.makedirs(image_dirs)
            image_path = os.path.join(image_dirs, image_name)
            try:
                image.save(image_path)
            except TypeError:
                image_name = image_name +'.'+ image.format
                image_path = "%s/%s" % (image_dirs, image_name)
                image.save(image_name)
            except  KeyError:
                image.save(image_path, 'JPEG')
            except IOError:
                image.mode = 'RGB'
                image.save(image_path)
            return "%s/%s" % (image_sub_path, image_name)

    def convert_date(self, s, site):
        if site.date_fmt:
            return datetime.strptime(s, site.date_fmt)
        else:
            return datetime.fromtimestamp(int(s))

    def _gen_district(self, elem, field_map, city, deal):
        district = self.get_text(elem, field_map, settings.DEAL_DIS)
        if district:
            district, flag = District.objects.get_or_create(name=district)
            district.city.add(city)
            deal.district.add(district)
        return district

    def _gen_shop(self, elem, field_map, city, deal, district=None):
        shop = self.get_text(elem, field_map, settings.DEAL_SHOP)
        if shop:
            url = self.get_text(elem, field_map, settings.SHOP_URL)
            telephone = self.get_text(elem, field_map, settings.SHOP_TEL)
            address = self.get_text(elem, field_map, settings.SHOP_ADDR)
            longitude = self.get_text(elem, field_map, settings.SHOP_LNG)
            latitude = self.get_text(elem, field_map, settings.SHOP_LAT)
            if isinstance(shop, list):
                items = zip(shop, telephone, address, longitude, latitude, url) 
                for item in items:
                    shop, flag = Shop.objects.get_or_create(name=item[0],  defaults={
                        'telephone':item[1],
                        'address': item[2],
                        'longitude': item[3], 
                        'latitude': item[4],
                        'url': item[5],
                    })
                    deal.shop.add(shop)
                    shop.city.add(city)
                    if district:
                        shop.district = district
                        shop.save()
            else:
                shop, flag = Shop.objects.get_or_create(name=shop, defaults={
                    'telephone': telephone,
                    'address': address,
                    'longitude': longitude,
                    'latitude': latitude,
                    'url': url,
                })
                shop.city.add(city)
                if district:
                    shop.district = district
                    shop.save()
        return shop

    def _gen_city(self, elem, field_map):
        division = self.get_text(elem, field_map, settings.DEAL_DIVISION)
        if division:
            division, flag = City.objects.get_or_create(name=division)
        else:
            division, flag= City.objects.get_or_create(name=u'全国')
        return division

    def _gen_deal(self, website, elem, field_map, city):
        print "ok"
        title = self.get_text(elem, field_map, settings.DEAL_TITLE)
        bought = self.get_text(elem, field_map, settings.DEAL_BOUGHT)
        deal_url = self.get_text(elem, field_map, settings.DEAL_URL)
        start_date = self.convert_date(self.get_text(elem, field_map, settings.DEAL_START_DATE), website)
        end_date = self.convert_date(self.get_text(elem, field_map, settings.DEAL_END_DATE), website)
        origin_price = self.filter_price(elem, field_map, settings.DEAL_ORIGIN_PRICE)
        price = self.filter_price(elem, field_map, settings.DEAL_PRICE)
        discount = self.filter_price(elem, field_map, settings.DEAL_DISCOUNT, origin_price, price)
        description = self.get_text(elem, field_map, settings.DEAL_DSR)
        image_url = self.get_text(elem, field_map, settings.DEAL_IMAGE)
        image = self.get_image(image_url, website)
        """
            deal, flag = Deal.objects.get_or_create(title=title, website=website, start_date=start_date,
                                                                    end_date=end_date, defaults={
                                                                    'bought': bought,
                                                                    'image': image,
                                                                    'deal_url':deal_url,
                                                                    'origin_price':origin_price,
                                                                    'price':price,
                                                                    'discount':discount,
                                                                    'description':description,
                                                                    })
            deal.division.add(city)
            return deal
        """

    def parse_deals_api(self, site):
        print site.name
        field_map = self.get_field_map(site)
        elems = self.get_elems(self.deal_url)
        for elem in elems:
            #try:
                city = self._gen_city(elem, field_map) 
                site.opened_city.add(city)
                deal = self._gen_deal(site, elem, field_map, city)
                #district = self._gen_district(elem, field_map, city, deal)
                #self._gen_shop(elem, field_map, city, deal, district)
            #except: 
                #with open('error.txt', 'a') as f:
                    #exc_type, exc_value, exc_tb = sys.exc_info()
                    #f.write("%s\t%s%s" %(site.name.encode('utf-8'), self.deal_url.encode('utf-8'),  os.linesep))
                    #f.write('[%s]' % datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
                    #traceback.print_exception(exc_type,
                    #                          exc_value,
                    #                          exc_tb, 
                    #                          limit=7,
                    #                          file=f)
                    #f.write('%s' % os.linesep)
                    #f.flush()
                break
                
class EnhanceCitySpider(CitySpider):
    def __init__(self, api_addr, api_list):
        super(self.__class__, self).__init__(api_addr, api_list)

    def get_elems(self, url):
        etree = self.create_etree(url)
        first_node = (sub for sub in etree.getchildren())
        childs = (child for node in first_node for  child in node.getchildren())
        return childs

class EnhanceDealSpider(DealSpider):
    def __init__(self, deal_url, *args, **kwargs):
        super(self.__class__, self).__init__(deal_url)

    def get_elems(self, url):
        etree = self.create_etree(url)
        first_node = (sub for sub in etree.getchildren())
        childs = (child for node in first_node  for  child in node.getchildren())
        return childs
